from fastapi import APIRouter, Depends, HTTPException, Query
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from typing import List, Dict, Any, Optional
from pydantic import BaseModel
from fastapi.responses import StreamingResponse
from io import BytesIO
import pandas as pd
from datetime import datetime
import json
import base64

# ðŸ”’ å¼•å…¥è§£å¯†åº“
from Crypto.Cipher import AES
from Crypto.Util.Padding import unpad

from app.core.database import get_db
# âš ï¸ æ³¨æ„ï¼šè¿™é‡Œæ²¿ç”¨ä½ çš„ ProductionLog æ¨¡åž‹
from app.models.production_log import ProductionLog
from app.schemas.production import ProductionLogCreate

router = APIRouter()

# ================= é…ç½®åŒº (å¿…é¡»ä¸Ž Client ç«¯å®Œå…¨ä¸€è‡´) =================
SECRET_KEY = b"MiniMES_2026_Ver0.4_Secure_Key!!" 
IV = b"MiniMES_IV_2026!"

# --- è¾…åŠ©å‡½æ•°ï¼šè§£å¯† ---
def decrypt_payload(encrypted_base64_str: str) -> dict:
    try:
        # 1. Base64 è§£ç  -> å¾—åˆ°åŠ å¯†çš„äºŒè¿›åˆ¶å­—èŠ‚
        ciphertext = base64.b64decode(encrypted_base64_str)
        
        # 2. åˆ›å»ºè§£å¯†å™¨
        cipher = AES.new(SECRET_KEY, AES.MODE_CBC, IV)
        
        # 3. è§£å¯† + åŽ»é™¤å¡«å…… (Unpad)
        decrypted_bytes = unpad(cipher.decrypt(ciphertext), AES.block_size)
        
        # 4. è¿˜åŽŸæˆ JSON å­—ç¬¦ä¸² -> å­—å…¸
        json_str = decrypted_bytes.decode('utf-8')
        return json.loads(json_str)
    except Exception as e:
        print(f"âŒ è§£å¯†å¤±è´¥è¯¦æƒ…: {e}")
        raise ValueError("Decryption failed")

# --- å®šä¹‰å“åº”æ¨¡åž‹ ---
class ProductionLogRead(BaseModel):
    id: int
    line_id: str
    device_id: str
    created_at: Any  
    payload: Dict[str, Any]

    class Config:
        from_attributes = True

# --- æŽ¥å£ 1: ä¸Šä¼ æ•°æ® (ä¿ç•™ AES è§£å¯†é€»è¾‘) ---
@router.post("/upload", response_model=dict)
async def upload_data(data: ProductionLogCreate, db: AsyncSession = Depends(get_db)):
    """
    æŽ¥æ”¶åŠ å¯†çš„ Payload -> è§£å¯† -> å­˜å…¥æ•°æ®åº“
    """
    try:
        # 1. ðŸ•µï¸â€â™‚ï¸ æ‰§è¡Œè§£å¯†
        print(f"ðŸ”’ æ”¶åˆ°å¯†æ–‡: {data.payload[:15]}...")
        try:
            decrypted_payload = decrypt_payload(data.payload)
            print(f"ðŸ”“ è§£å¯†æˆåŠŸ: {decrypted_payload}")
        except Exception as e:
            raise HTTPException(status_code=400, detail="Invalid Encrypted Payload")

        # 2. æ³¨å…¥æ—¶é—´æˆ³
        final_payload = decrypted_payload.copy()
        final_payload["edge_timestamp"] = data.timestamp

        # 3. åˆ›å»ºæ•°æ®åº“å¯¹è±¡
        new_log = ProductionLog(
            line_id=data.line_id,
            device_id=data.device_id,
            operator_id=data.operator_id,
            source_type=data.source_type,
            payload=final_payload 
        )

        # 4. å†™å…¥
        db.add(new_log)
        await db.commit()
        await db.refresh(new_log)

        return {
            "code": 200, 
            "msg": "success", 
            "data": {"record_id": new_log.id}
        }
        
    except HTTPException as he:
        raise he
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿé”™è¯¯: {str(e)}")
        await db.rollback()
        raise HTTPException(status_code=500, detail=f"Server Error: {str(e)}")

# --- æŽ¥å£ 2: èŽ·å–åˆ—è¡¨ (ðŸ”¥å·²å‡çº§ï¼šæ”¯æŒç­›é€‰) ---
@router.get("/list", response_model=List[ProductionLogRead])
async def get_logs(
    skip: int = 0, 
    limit: int = 20, 
    # ðŸ‘‡ æ–°å¢žï¼šç­›é€‰å‚æ•°
    line_id: Optional[str] = Query(None, description="äº§çº¿ID (å¦‚ LINE-A)"),
    start_time: Optional[float] = Query(None, description="å¼€å§‹æ—¶é—´æˆ³ (ç§’)"),
    end_time: Optional[float] = Query(None, description="ç»“æŸæ—¶é—´æˆ³ (ç§’)"),
    db: AsyncSession = Depends(get_db)
):
    # 1. åŸºç¡€æŸ¥è¯¢
    stmt = select(ProductionLog).order_by(ProductionLog.id.desc())

    # 2. åŠ¨æ€æ‹¼æŽ¥ç­›é€‰æ¡ä»¶
    if line_id:
        stmt = stmt.where(ProductionLog.line_id == line_id)
    
    # æ³¨æ„ï¼šä½ çš„æ¨¡åž‹é‡Œæ—¶é—´å­—æ®µå« created_at (DateTimeç±»åž‹)ï¼Œå‰ç«¯ä¼ çš„æ˜¯æ—¶é—´æˆ³ (Float)
    # æ‰€ä»¥è¿™é‡Œéœ€è¦è½¬æ¢ä¸€ä¸‹
    if start_time:
        dt_start = datetime.fromtimestamp(start_time)
        stmt = stmt.where(ProductionLog.created_at >= dt_start)
        
    if end_time:
        dt_end = datetime.fromtimestamp(end_time)
        stmt = stmt.where(ProductionLog.created_at <= dt_end)

    # 3. åˆ†é¡µ
    stmt = stmt.offset(skip).limit(limit)

    # 4. æ‰§è¡Œ
    result = await db.execute(stmt)
    logs = result.scalars().all()
    return logs

# --- æŽ¥å£ 3: Excel å¯¼å‡º (ä¿ç•™åŽŸé€»è¾‘) ---
@router.get("/export")
async def export_data(db: AsyncSession = Depends(get_db)):
    try:
        stmt = select(ProductionLog).order_by(ProductionLog.id.desc())
        result = await db.execute(stmt)
        logs = result.scalars().all()
        
        if not logs:
            raise HTTPException(status_code=404, detail="No data")

        data_list = []
        for log in logs:
            row = {
                "ID": log.id,
                "Line": log.line_id,
                "Device": log.device_id,
                "Time": log.created_at.strftime("%Y-%m-%d %H:%M:%S") if log.created_at else "",
            }
            if log.payload and isinstance(log.payload, dict):
                row.update(log.payload)
            data_list.append(row)

        df = pd.DataFrame(data_list)
        output = BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df.to_excel(writer, index=False)
        output.seek(0)
        filename = f"MiniMES_Export_{datetime.now().strftime('%Y%m%d')}.xlsx"
        headers = {'Content-Disposition': f'attachment; filename="{filename}"'}
        return StreamingResponse(output, headers=headers, media_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))